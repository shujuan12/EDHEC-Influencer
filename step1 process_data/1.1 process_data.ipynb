{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## è¯»å–csvï¼Œå¹¶å¤„ç†ç”¨æˆ·å’Œå¾®åšæ•°æ®\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# è¯»å–æ•°æ®\n",
    "users = pd.read_csv('../data/users.csv')\n",
    "posts = pd.read_csv('../data/posts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20 entries, 0 to 19\n",
      "Data columns (total 10 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   user_id         20 non-null     int64  \n",
      " 1   nickname        20 non-null     object \n",
      " 2   gender          20 non-null     object \n",
      " 3   avatar          20 non-null     object \n",
      " 4   desc            16 non-null     object \n",
      " 5   ip_location     0 non-null      float64\n",
      " 6   follows         20 non-null     int64  \n",
      " 7   fans            20 non-null     object \n",
      " 8   tag_list        0 non-null      float64\n",
      " 9   last_modify_ts  20 non-null     int64  \n",
      "dtypes: float64(2), int64(3), object(5)\n",
      "memory usage: 1.7+ KB\n"
     ]
    }
   ],
   "source": [
    "users.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9765 entries, 0 to 9764\n",
      "Data columns (total 16 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   note_id           9765 non-null   int64  \n",
      " 1   content           9759 non-null   object \n",
      " 2   create_time       9765 non-null   int64  \n",
      " 3   create_date_time  9765 non-null   object \n",
      " 4   liked_count       9765 non-null   int64  \n",
      " 5   comments_count    9765 non-null   int64  \n",
      " 6   shared_count      9765 non-null   int64  \n",
      " 7   last_modify_ts    9765 non-null   int64  \n",
      " 8   note_url          9765 non-null   object \n",
      " 9   ip_location       5497 non-null   object \n",
      " 10  user_id           9765 non-null   int64  \n",
      " 11  nickname          9765 non-null   object \n",
      " 12  gender            9765 non-null   object \n",
      " 13  profile_url       9765 non-null   object \n",
      " 14  avatar            9765 non-null   object \n",
      " 15  source_keyword    0 non-null      float64\n",
      "dtypes: float64(1), int64(7), object(8)\n",
      "memory usage: 1.2+ MB\n"
     ]
    }
   ],
   "source": [
    "posts.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å°†ç²‰ä¸æ•°è½¬åŒ–ä¸ºnumber\n",
    "def parse_fans(value):\n",
    "    if isinstance(value, str):\n",
    "        if 'ä¸‡' in value:\n",
    "            return float(value.replace('ä¸‡', '')) * 10000\n",
    "        try:\n",
    "            return float(value)\n",
    "        except:\n",
    "            return None\n",
    "    return value\n",
    "users['fans'] = users['fans'].apply(parse_fans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ€§åˆ«è½¬åŒ–\n",
    "users['gender'] = users['gender'].map({'ç”·': 'male', 'å¥³': 'female', 'm': 'male', 'f': 'female'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20 entries, 0 to 19\n",
      "Data columns (total 5 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   user_id  20 non-null     int64  \n",
      " 1   gender   20 non-null     object \n",
      " 2   desc     16 non-null     object \n",
      " 3   follows  20 non-null     int64  \n",
      " 4   fans     20 non-null     float64\n",
      "dtypes: float64(1), int64(2), object(2)\n",
      "memory usage: 928.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "# åˆ é™¤å¤šä½™åˆ—\n",
    "drop_cols = [\n",
    "    'nickname', 'avatar', 'ip_location',\n",
    "    'tag_list', 'last_modify_ts'\n",
    "]\n",
    "users.drop(columns=drop_cols, inplace=True, errors='ignore')\n",
    "users.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>create_time</th>\n",
       "      <th>create_date_time</th>\n",
       "      <th>liked_count</th>\n",
       "      <th>comments_count</th>\n",
       "      <th>shared_count</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>å¡ç²‰è„±å¦†æ˜Ÿäººï¼Œçœ‹è¿™ç¯‡ï¼ä»Šå¤©æ˜¯å°è¯¾å ‚æœ€åä¸€è®²ã€ä»ªå™¨æ´é¢é˜²æ™’ç¯‡ã€‘ï¼Œè®°å¾—æ¥å¬å“¦ï¼#æä½³ç¦# #æä½³...</td>\n",
       "      <td>1746966601</td>\n",
       "      <td>2025-05-11 12:30:01+08:00</td>\n",
       "      <td>464</td>\n",
       "      <td>102</td>\n",
       "      <td>48</td>\n",
       "      <td>1968758563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ä¸åŒéœ€æ±‚ä¸åŒé¢„ç®—ï¼Œè¿›æ¥å¯¹å·å…¥åº§â€¼é¢„å‘Šä¸€ä¸‹ï¼Œæ¥ä¸‹æ¥çš„å°è¯¾å ‚èŠ‚å¥ğŸ‘‡ã€å½©å¦†ç¯‡ã€‘ã€ä»ªå™¨æ´é¢é˜²æ™’ç¯‡ã€‘ï¼Œ...</td>\n",
       "      <td>1746878400</td>\n",
       "      <td>2025-05-10 12:00:00+08:00</td>\n",
       "      <td>387</td>\n",
       "      <td>85</td>\n",
       "      <td>20</td>\n",
       "      <td>1968758563</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content  create_time  \\\n",
       "0  å¡ç²‰è„±å¦†æ˜Ÿäººï¼Œçœ‹è¿™ç¯‡ï¼ä»Šå¤©æ˜¯å°è¯¾å ‚æœ€åä¸€è®²ã€ä»ªå™¨æ´é¢é˜²æ™’ç¯‡ã€‘ï¼Œè®°å¾—æ¥å¬å“¦ï¼#æä½³ç¦# #æä½³...   1746966601   \n",
       "1  ä¸åŒéœ€æ±‚ä¸åŒé¢„ç®—ï¼Œè¿›æ¥å¯¹å·å…¥åº§â€¼é¢„å‘Šä¸€ä¸‹ï¼Œæ¥ä¸‹æ¥çš„å°è¯¾å ‚èŠ‚å¥ğŸ‘‡ã€å½©å¦†ç¯‡ã€‘ã€ä»ªå™¨æ´é¢é˜²æ™’ç¯‡ã€‘ï¼Œ...   1746878400   \n",
       "\n",
       "            create_date_time  liked_count  comments_count  shared_count  \\\n",
       "0  2025-05-11 12:30:01+08:00          464             102            48   \n",
       "1  2025-05-10 12:00:00+08:00          387              85            20   \n",
       "\n",
       "      user_id  \n",
       "0  1968758563  \n",
       "1  1968758563  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# åˆ é™¤å¤šä½™åˆ—\n",
    "drop_cols = [\n",
    "    'note_id', 'last_modify_ts', 'note_url', 'ip_location',\n",
    "    'nickname', 'gender','profile_url','avatar','source_keyword'\n",
    "]\n",
    "posts.drop(columns=drop_cols, inplace=True, errors='ignore')\n",
    "posts.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count      9765.000000\n",
       "mean        349.594060\n",
       "std        2385.274291\n",
       "min           0.000000\n",
       "25%           3.000000\n",
       "50%          18.000000\n",
       "75%         218.000000\n",
       "max      179101.000000\n",
       "Name: shared_count, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts['shared_count'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç”Ÿæˆåˆ†ç±»æ ‡ç­¾ï¼ˆè½¬å‘é‡å¤šåˆ†ç±»ï¼‰\n",
    "def classify_shared_count(x):\n",
    "    try:\n",
    "        x = int(x)\n",
    "        if x <= 3:\n",
    "            return 0\n",
    "        elif x <= 18:\n",
    "            return 1\n",
    "        elif x <= 218:\n",
    "            return 2\n",
    "        else:\n",
    "            return 3\n",
    "    except:\n",
    "        return None\n",
    "posts['shared_class'] = posts['shared_count'].apply(classify_shared_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# åˆå¹¶ï¼šæ ¹æ® user_id å…³è”\n",
    "df = posts.merge(users, on='user_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11104 entries, 0 to 11103\n",
      "Data columns (total 12 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   content           11097 non-null  object \n",
      " 1   create_time       11104 non-null  int64  \n",
      " 2   create_date_time  11104 non-null  object \n",
      " 3   liked_count       11104 non-null  int64  \n",
      " 4   comments_count    11104 non-null  int64  \n",
      " 5   shared_count      11104 non-null  int64  \n",
      " 6   user_id           11104 non-null  int64  \n",
      " 7   shared_class      11104 non-null  int64  \n",
      " 8   gender            11104 non-null  object \n",
      " 9   desc              9346 non-null   object \n",
      " 10  follows           11104 non-null  int64  \n",
      " 11  fans              11104 non-null  float64\n",
      "dtypes: float64(1), int64(7), object(4)\n",
      "memory usage: 1.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## æ–‡æœ¬ç‰¹å¾"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#æ–‡æœ¬ç‰¹å¾\n",
    "df['content'] = df['content'].fillna(' ')\n",
    "df['desc'] = df['desc'].fillna(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba #åˆ†è¯\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from gensim.models.word2vec import Word2Vec \n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word2vec:ä½¿ç”¨word2vecå¾—åˆ°æ¯ä¸ªè¯çš„è¯å‘é‡ï¼Œå°†å¥å­æ‰€æœ‰è¯å–å‡å€¼å¾—åˆ°å¥å­çš„å‘é‡ï¼Œç”¨æ¥è¡¨å¾æ ·æœ¬ä¸­çš„æ–‡æœ¬\n",
    "def generate_wv(texts):\n",
    "    text_list = []\n",
    "    for text in tqdm(texts):\n",
    "        text_list.append(list(jieba.cut(text)))\n",
    "    wv_model= Word2Vec(text_list, min_count=1, vector_size = 10, sg = 1)\n",
    "    text_embed_list = []\n",
    "    \n",
    "    for sentence in text_list:\n",
    "        word_embed_list = []\n",
    "        for word in sentence:\n",
    "            word_embed_list.append(wv_model.wv[word])\n",
    "        text_embed_list.append(np.array(word_embed_list).mean(0))\n",
    "    \n",
    "    return np.array(text_embed_list)\n",
    "\n",
    "# tfidf-svdï¼šåˆ©ç”¨ç¨€ç–çŸ©é˜µçš„æ–¹æ³•æŠ½å–æ¯ä¸ªæ ·æœ¬çš„tfidfå‘é‡ï¼Œå†åˆ©ç”¨svdé™ç»´å¾—åˆ°æ–‡æœ¬ç‰¹å¾\n",
    "def build_tfidf_svd_matrix(texts, n_output):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    corpus = []\n",
    "    for text in texts:\n",
    "        words = list(jieba.cut(str(text)))\n",
    "        use_words = []\n",
    "        for word in words:\n",
    "            use_words.append(word)\n",
    "        corpus.append(' '.join(use_words))\n",
    "    tfidf_vec = TfidfVectorizer()\n",
    "    tfidf_matrix = tfidf_vec.fit_transform(corpus)\n",
    "    svd = TruncatedSVD(n_components=n_output, n_iter=7, random_state=42)\n",
    "    tf_idf_svd = svd.fit_transform(tfidf_matrix)\n",
    "    \n",
    "    return tf_idf_svd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, BertModel\n",
    "import torch\n",
    "\n",
    "\n",
    "def classify_reviews(df, text_col='content', output_col='sentiment_class', batch_size=10):\n",
    "    # ç±»åˆ«æ˜ å°„\n",
    "    # class_names = {0: \"è´Ÿé¢\", 1: \"æ­£é¢\"}\n",
    "    class_names = {0: 0, 1: 1}\n",
    "    df[output_col] = None\n",
    "\n",
    "    # è®¾å¤‡è®¾ç½®ï¼ˆä½¿ç”¨GPUå¦‚æœå¯ç”¨ï¼‰\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    # åŠ è½½é¢„è®­ç»ƒæ¨¡å‹å’Œåˆ†è¯å™¨\n",
    "    model_name = '../BERT-weibo' \n",
    "    tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "    model = BertForSequenceClassification.from_pretrained(model_name).to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    for i in range(0, len(df), batch_size):\n",
    "        batch_texts = df[text_col][i:i+batch_size].astype(str).tolist()\n",
    "\n",
    "        # ç¼–ç \n",
    "        inputs = tokenizer(batch_texts, padding=True, truncation=True, return_tensors=\"pt\").to(device)\n",
    "\n",
    "        # æ¨ç†\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "            predictions = torch.argmax(outputs.logits, dim=-1)\n",
    "\n",
    "        # æ·»åŠ ç»“æœ\n",
    "        df.loc[i:i+batch_size-1, output_col] = [class_names[pred.item()] for pred in predictions]\n",
    "\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/11104 [00:00<?, ?it/s]Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\lyh\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 0.488 seconds.\n",
      "Prefix dict has been built successfully.\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11104/11104 [00:03<00:00, 3291.34it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11104/11104 [00:00<00:00, 11411.58it/s]\n"
     ]
    }
   ],
   "source": [
    "weibotext_wv_embed = generate_wv(df['content']) \n",
    "df['content_wv_embed'] = list(weibotext_wv_embed) #å¾®åšå†…å®¹è¯å‘é‡\n",
    "user_intro_wv_embed = generate_wv(df['desc'])\n",
    "df['desc_wv_embed'] = list(user_intro_wv_embed) #ç”¨æˆ·ç®€ä»‹è¯å‘é‡\n",
    "\n",
    "weibotext_tfidf = build_tfidf_svd_matrix(df['content'], 10)\n",
    "df['content_tfidf'] = list(weibotext_tfidf) #å¾®åšå†…å®¹tfidf+svd\n",
    "user_intro_tfidf = build_tfidf_svd_matrix(df['desc'], 10)\n",
    "df['desc_tfidf'] = list(user_intro_tfidf)#ç”¨æˆ·ç®€ä»‹tfidf+svd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11104 entries, 0 to 11103\n",
      "Data columns (total 16 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   content           11104 non-null  object \n",
      " 1   create_time       11104 non-null  int64  \n",
      " 2   create_date_time  11104 non-null  object \n",
      " 3   liked_count       11104 non-null  int64  \n",
      " 4   comments_count    11104 non-null  int64  \n",
      " 5   shared_count      11104 non-null  int64  \n",
      " 6   user_id           11104 non-null  int64  \n",
      " 7   shared_class      11104 non-null  int64  \n",
      " 8   gender            11104 non-null  object \n",
      " 9   desc              11104 non-null  object \n",
      " 10  follows           11104 non-null  int64  \n",
      " 11  fans              11104 non-null  float64\n",
      " 12  content_wv_embed  11104 non-null  object \n",
      " 13  desc_wv_embed     11104 non-null  object \n",
      " 14  content_tfidf     11104 non-null  object \n",
      " 15  desc_tfidf        11104 non-null  object \n",
      "dtypes: float64(1), int64(7), object(8)\n",
      "memory usage: 1.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å†…å®¹é•¿åº¦\n",
    "df['content_len'] = df['content'].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "g:\\Anaconda3\\envs\\trasformers\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:439: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:263.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11104 entries, 0 to 11103\n",
      "Data columns (total 18 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   content           11104 non-null  object \n",
      " 1   create_time       11104 non-null  int64  \n",
      " 2   create_date_time  11104 non-null  object \n",
      " 3   liked_count       11104 non-null  int64  \n",
      " 4   comments_count    11104 non-null  int64  \n",
      " 5   shared_count      11104 non-null  int64  \n",
      " 6   user_id           11104 non-null  int64  \n",
      " 7   shared_class      11104 non-null  int64  \n",
      " 8   gender            11104 non-null  object \n",
      " 9   desc              11104 non-null  object \n",
      " 10  follows           11104 non-null  int64  \n",
      " 11  fans              11104 non-null  float64\n",
      " 12  content_wv_embed  11104 non-null  object \n",
      " 13  desc_wv_embed     11104 non-null  object \n",
      " 14  content_tfidf     11104 non-null  object \n",
      " 15  desc_tfidf        11104 non-null  object \n",
      " 16  content_len       11104 non-null  int64  \n",
      " 17  sentiment_class   11104 non-null  object \n",
      "dtypes: float64(1), int64(8), object(9)\n",
      "memory usage: 1.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df = classify_reviews(df)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## æ—¶é—´ç‰¹å¾"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from dateutil import parser\n",
    "\n",
    "def apply_weibo_creatime(x):\n",
    "    date_obj = pd.to_datetime(x)\n",
    "    # date_obj = datetime.strptime(x, '%Y-%m-%d %H:%M:%S')\n",
    "    return pd.Series({\n",
    "        'post_day':date_obj.day,\n",
    "        'post_weekday':date_obj.weekday(),\n",
    "        'post_month':date_obj.month, \n",
    "        'post_hour':date_obj.hour, \n",
    "        'post_minute':date_obj.minute,\n",
    "        'post_year':date_obj.year,\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_day</th>\n",
       "      <th>post_weekday</th>\n",
       "      <th>post_month</th>\n",
       "      <th>post_hour</th>\n",
       "      <th>post_minute</th>\n",
       "      <th>post_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>30</td>\n",
       "      <td>2025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>2025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>53</td>\n",
       "      <td>2025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>30</td>\n",
       "      <td>2025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>2025</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   post_day  post_weekday  post_month  post_hour  post_minute  post_year\n",
       "0        11             6           5         12           30       2025\n",
       "1        10             5           5         12            0       2025\n",
       "2         9             4           5         14           53       2025\n",
       "3         8             3           5         12           30       2025\n",
       "4         7             2           5         12           31       2025"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# æ—¶é—´ç‰¹å¾\n",
    "df_weibo_create_time_feature = df['create_date_time'].apply(apply_weibo_creatime)\n",
    "df_weibo_create_time_feature.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df, df_weibo_create_time_feature], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11104 entries, 0 to 11103\n",
      "Data columns (total 24 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   content           11104 non-null  object \n",
      " 1   create_time       11104 non-null  int64  \n",
      " 2   create_date_time  11104 non-null  object \n",
      " 3   liked_count       11104 non-null  int64  \n",
      " 4   comments_count    11104 non-null  int64  \n",
      " 5   shared_count      11104 non-null  int64  \n",
      " 6   user_id           11104 non-null  int64  \n",
      " 7   shared_class      11104 non-null  int64  \n",
      " 8   gender            11104 non-null  object \n",
      " 9   desc              11104 non-null  object \n",
      " 10  follows           11104 non-null  int64  \n",
      " 11  fans              11104 non-null  float64\n",
      " 12  content_wv_embed  11104 non-null  object \n",
      " 13  desc_wv_embed     11104 non-null  object \n",
      " 14  content_tfidf     11104 non-null  object \n",
      " 15  desc_tfidf        11104 non-null  object \n",
      " 16  content_len       11104 non-null  int64  \n",
      " 17  sentiment_class   11104 non-null  object \n",
      " 18  post_day          11104 non-null  int64  \n",
      " 19  post_weekday      11104 non-null  int64  \n",
      " 20  post_month        11104 non-null  int64  \n",
      " 21  post_hour         11104 non-null  int64  \n",
      " 22  post_minute       11104 non-null  int64  \n",
      " 23  post_year         11104 non-null  int64  \n",
      "dtypes: float64(1), int64(14), object(9)\n",
      "memory usage: 2.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2776/2776 [01:44<00:00, 26.57it/s]\n"
     ]
    }
   ],
   "source": [
    "# 1. åŠ è½½BERT tokenizerå’Œæ¨¡å‹\n",
    "tokenizer = BertTokenizer.from_pretrained('../bert-base-chinese')\n",
    "model = BertModel.from_pretrained('../bert-base-chinese')\n",
    "model.eval()  # å…³é—­dropoutç­‰è®­ç»ƒç‰¹æ€§\n",
    "\n",
    "# å¦‚æœæœ‰GPUå¯ç”¨åˆ™ä½¿ç”¨GPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "# 3. æ‰¹é‡æå–embeddingå‡½æ•°\n",
    "def get_batch_embeddings(texts, batch_size=8):\n",
    "    embeddings = []\n",
    "    for i in tqdm(range(0, len(texts), batch_size)):\n",
    "        batch_texts = texts[i:i+batch_size]\n",
    "        # ç¼–ç \n",
    "        inputs = tokenizer(batch_texts, return_tensors='pt', padding=True, truncation=True, max_length=128)\n",
    "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "        # æ¨ç†\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "            cls_embeddings = outputs.last_hidden_state[:, 0, :]  # shape: (batch_size, 768)\n",
    "            cls_embeddings = cls_embeddings.cpu().numpy()\n",
    "            embeddings.extend(cls_embeddings)\n",
    "    return embeddings\n",
    "\n",
    "# 4. è·å–embeddingå¹¶å­˜å…¥DataFrame\n",
    "df['embedding'] = get_batch_embeddings(df['content'].tolist(), batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11104 entries, 0 to 11103\n",
      "Data columns (total 33 columns):\n",
      " #   Column                         Non-Null Count  Dtype   \n",
      "---  ------                         --------------  -----   \n",
      " 0   content                        11104 non-null  object  \n",
      " 1   create_time                    11104 non-null  int64   \n",
      " 2   create_date_time               11104 non-null  object  \n",
      " 3   liked_count                    11104 non-null  int64   \n",
      " 4   comments_count                 11104 non-null  int64   \n",
      " 5   shared_count                   11104 non-null  int64   \n",
      " 6   user_id                        11104 non-null  category\n",
      " 7   shared_class                   11104 non-null  int64   \n",
      " 8   gender                         11104 non-null  object  \n",
      " 9   desc                           11104 non-null  object  \n",
      " 10  follows                        11104 non-null  int64   \n",
      " 11  fans                           11104 non-null  float64 \n",
      " 12  content_wv_embed               11104 non-null  object  \n",
      " 13  desc_wv_embed                  11104 non-null  object  \n",
      " 14  content_tfidf                  11104 non-null  object  \n",
      " 15  desc_tfidf                     11104 non-null  object  \n",
      " 16  content_len                    11104 non-null  int64   \n",
      " 17  sentiment_class                11104 non-null  object  \n",
      " 18  post_day                       11104 non-null  int64   \n",
      " 19  post_weekday                   11104 non-null  int64   \n",
      " 20  post_month                     11104 non-null  int64   \n",
      " 21  post_hour                      11104 non-null  int64   \n",
      " 22  post_minute                    11104 non-null  int64   \n",
      " 23  post_year                      11104 non-null  int64   \n",
      " 24  target_encode_0                11104 non-null  float64 \n",
      " 25  target_encode_1                11104 non-null  float64 \n",
      " 26  target_encode_2                11104 non-null  float64 \n",
      " 27  target_encode_3                11104 non-null  float64 \n",
      " 28  target_encode_cnt              11104 non-null  float64 \n",
      " 29  userid_idx                     11104 non-null  category\n",
      " 30  cross_userid_idx_post_hour     11104 non-null  int64   \n",
      " 31  cross_userid_idx_post_weekday  11104 non-null  int64   \n",
      " 32  embedding                      11104 non-null  object  \n",
      "dtypes: category(2), float64(6), int64(15), object(10)\n",
      "memory usage: 2.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. å¯é€‰ä¿å­˜\n",
    "import pickle\n",
    "with open('bert_data.pkl', 'wb') as f:\n",
    "    pickle.dump(df, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trasformers",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
