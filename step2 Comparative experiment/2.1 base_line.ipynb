{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_features_from_file(\n",
    "    file_path,\n",
    "    continue_feature_list,\n",
    "    cat_feature_list,\n",
    "    hidden_feature_list,\n",
    "    target_col='shared_class',\n",
    "    scaler=None\n",
    "):\n",
    "    \"\"\"\n",
    "    从文件中读取数据并预处理特征。适配特征消融实验，支持部分特征为空。\n",
    "\n",
    "    参数：\n",
    "        file_path : str\n",
    "            pkl 文件路径。\n",
    "        continue_feature_list : list of str\n",
    "            连续特征列名。\n",
    "        cat_feature_list : list of str\n",
    "            类别特征列名。\n",
    "        hidden_feature_list : list of str\n",
    "            向量/嵌入特征列名。\n",
    "        target_col : str\n",
    "            标签列名，默认 'shared_class'。\n",
    "        scaler : StandardScaler or None\n",
    "            可选。若传入，将复用已有 scaler。\n",
    "\n",
    "    返回：\n",
    "        X : pd.DataFrame\n",
    "        y : pd.Series\n",
    "    \"\"\"\n",
    "    with open(file_path, 'rb') as f:\n",
    "        df = pickle.load(f)\n",
    "\n",
    "    feature_parts = []\n",
    "\n",
    "    # 处理连续特征\n",
    "    if continue_feature_list:\n",
    "        if scaler is None:\n",
    "            scaler = StandardScaler()\n",
    "            X_cont_scaled = scaler.fit_transform(df[continue_feature_list])\n",
    "        else:\n",
    "            X_cont_scaled = scaler.transform(df[continue_feature_list])\n",
    "        cont_scaled_df = pd.DataFrame(X_cont_scaled, columns=continue_feature_list, index=df.index)\n",
    "        feature_parts.append(cont_scaled_df)\n",
    "\n",
    "    # 处理类别特征\n",
    "    if cat_feature_list:\n",
    "        df[cat_feature_list] = df[cat_feature_list].astype(str)\n",
    "        cat_encoded_df = pd.get_dummies(df[cat_feature_list], drop_first=False)\n",
    "        feature_parts.append(cat_encoded_df)\n",
    "\n",
    "    # 处理嵌入特征\n",
    "    def expand_vector_features(df, feature_names):\n",
    "        expanded = []\n",
    "        for col in feature_names:\n",
    "            # 若该列为空（或全为None），跳过\n",
    "            if df[col].isnull().all():\n",
    "                continue\n",
    "            expanded_cols = pd.DataFrame(df[col].tolist(), \n",
    "                                         index=df.index,\n",
    "                                         columns=[f\"{col}_{i}\" for i in range(len(df[col].iloc[0]))])\n",
    "            expanded.append(expanded_cols)\n",
    "        return pd.concat(expanded, axis=1) if expanded else pd.DataFrame(index=df.index)\n",
    "\n",
    "    if hidden_feature_list:\n",
    "        X_hidden = expand_vector_features(df, hidden_feature_list)\n",
    "        feature_parts.append(X_hidden)\n",
    "\n",
    "\n",
    "    X = pd.concat([part.reset_index(drop=True) for part in feature_parts], axis=1).astype(float)\n",
    "    y = df[target_col]\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_classifiers(X_train, X_test, y_train, y_test):\n",
    "\n",
    "    # 所有模型及其名称（可扩展）\n",
    "    models = {\n",
    "        \"Logistic Regression\": LogisticRegression(random_state=42, max_iter=1000),\n",
    "        \"Support Vector Machine (SVM)\": SVC(random_state=42),\n",
    "        \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
    "        \"Random Forest\": RandomForestClassifier(random_state=42)\n",
    "    }\n",
    "\n",
    "    # 遍历模型并评估\n",
    "    for name, model in models.items():\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "        precision = precision_score(y_test, y_pred, average='weighted')\n",
    "        recall = recall_score(y_test, y_pred, average='weighted')\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "        print(f\"\\n{name}:\")\n",
    "        print(f\"F1 Score: {f1:.4f}\")\n",
    "        print(f\"Precision: {precision:.4f}\")\n",
    "        print(f\"Recall: {recall:.4f}\")\n",
    "        print(f\"Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(continue_features, cat_features, hidden_features):\n",
    "    # 获得特征\n",
    "    X, y = prepare_features_from_file(\n",
    "    file_path='../data/bert_data.pkl',\n",
    "    continue_feature_list=continue_features,\n",
    "    cat_feature_list=cat_features,\n",
    "    hidden_feature_list=hidden_features\n",
    ")\n",
    "    # 将数据分为训练集和测试集（80%训练集，20%测试集）\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    evaluate_classifiers(X_train, X_test, y_train, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/luyang/anaconda3/envs/llm/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logistic Regression:\n",
      "F1 Score: 0.6516\n",
      "Precision: 0.6519\n",
      "Recall: 0.6515\n",
      "Accuracy: 0.6515\n",
      "\n",
      "Support Vector Machine (SVM):\n",
      "F1 Score: 0.6703\n",
      "Precision: 0.6768\n",
      "Recall: 0.6695\n",
      "Accuracy: 0.6695\n",
      "\n",
      "Decision Tree:\n",
      "F1 Score: 0.6924\n",
      "Precision: 0.6929\n",
      "Recall: 0.6920\n",
      "Accuracy: 0.6920\n",
      "\n",
      "Random Forest:\n",
      "F1 Score: 0.7493\n",
      "Precision: 0.7532\n",
      "Recall: 0.7501\n",
      "Accuracy: 0.7501\n"
     ]
    }
   ],
   "source": [
    "# 全部特征\n",
    "continue_features = [ \"create_time\", \"follows\", \"fans\", \"content_len\"]\n",
    "\n",
    "cat_features = [ \"gender\", \"sentiment_class\",\"post_day\", \"post_weekday\", \n",
    "                  \"post_month\", \"post_hour\", \"post_minute\"]\n",
    "\n",
    "hidden_features = [ \"content_wv_embed\", \"desc_wv_embed\", \n",
    "                    \"content_tfidf\", \"desc_tfidf\", \"embedding\"]\n",
    "train(continue_features, cat_features, hidden_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logistic Regression:\n",
      "F1 Score: 0.5098\n",
      "Precision: 0.5177\n",
      "Recall: 0.5110\n",
      "Accuracy: 0.5110\n",
      "\n",
      "Support Vector Machine (SVM):\n",
      "F1 Score: 0.6259\n",
      "Precision: 0.6364\n",
      "Recall: 0.6249\n",
      "Accuracy: 0.6249\n",
      "\n",
      "Decision Tree:\n",
      "F1 Score: 0.7048\n",
      "Precision: 0.7052\n",
      "Recall: 0.7046\n",
      "Accuracy: 0.7046\n",
      "\n",
      "Random Forest:\n",
      "F1 Score: 0.7498\n",
      "Precision: 0.7525\n",
      "Recall: 0.7501\n",
      "Accuracy: 0.7501\n"
     ]
    }
   ],
   "source": [
    "# 没有文本特征\n",
    "continue_features = [ \"create_time\", \"follows\", \"fans\", \"content_len\"]\n",
    "\n",
    "cat_features = [ \"gender\", \"sentiment_class\",\"post_day\", \"post_weekday\", \n",
    "                  \"post_month\", \"post_hour\", \"post_minute\"]\n",
    "\n",
    "hidden_features = []\n",
    "train(continue_features, cat_features, hidden_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/luyang/anaconda3/envs/llm/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logistic Regression:\n",
      "F1 Score: 0.6516\n",
      "Precision: 0.6521\n",
      "Recall: 0.6520\n",
      "Accuracy: 0.6520\n",
      "\n",
      "Support Vector Machine (SVM):\n",
      "F1 Score: 0.6625\n",
      "Precision: 0.6678\n",
      "Recall: 0.6623\n",
      "Accuracy: 0.6623\n",
      "\n",
      "Decision Tree:\n",
      "F1 Score: 0.6963\n",
      "Precision: 0.6972\n",
      "Recall: 0.6956\n",
      "Accuracy: 0.6956\n",
      "\n",
      "Random Forest:\n",
      "F1 Score: 0.7552\n",
      "Precision: 0.7579\n",
      "Recall: 0.7560\n",
      "Accuracy: 0.7560\n"
     ]
    }
   ],
   "source": [
    "# 没有类别特征\n",
    "continue_features = [\"create_time\", \"follows\", \"fans\", \"content_len\"]\n",
    "\n",
    "cat_features = []\n",
    "\n",
    "hidden_features = [ \"content_wv_embed\", \"desc_wv_embed\", \n",
    "                    \"content_tfidf\", \"desc_tfidf\", \"embedding\"]\n",
    "\n",
    "train(continue_features, cat_features, hidden_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/luyang/anaconda3/envs/llm/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logistic Regression:\n",
      "F1 Score: 0.6317\n",
      "Precision: 0.6325\n",
      "Recall: 0.6312\n",
      "Accuracy: 0.6312\n",
      "\n",
      "Support Vector Machine (SVM):\n",
      "F1 Score: 0.6612\n",
      "Precision: 0.6682\n",
      "Recall: 0.6614\n",
      "Accuracy: 0.6614\n",
      "\n",
      "Decision Tree:\n",
      "F1 Score: 0.6412\n",
      "Precision: 0.6406\n",
      "Recall: 0.6421\n",
      "Accuracy: 0.6421\n",
      "\n",
      "Random Forest:\n",
      "F1 Score: 0.7470\n",
      "Precision: 0.7540\n",
      "Recall: 0.7479\n",
      "Accuracy: 0.7479\n"
     ]
    }
   ],
   "source": [
    "# 没有连续特征\n",
    "continue_features = []\n",
    "\n",
    "cat_features = [ \"gender\", \"sentiment_class\",\"post_day\", \"post_weekday\", \n",
    "                  \"post_month\", \"post_hour\", \"post_minute\"]\n",
    "\n",
    "hidden_features = [ \"content_wv_embed\", \"desc_wv_embed\", \n",
    "                    \"content_tfidf\", \"desc_tfidf\", \"embedding\"]\n",
    "\n",
    "train(continue_features, cat_features, hidden_features)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trasformers",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
